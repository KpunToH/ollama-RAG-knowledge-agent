{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f546e15-ffdd-4ba1-9f3e-2a6fad3439d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write path to your docx and pdf docs here\n",
    "rag_path = r\"your\\path\\here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88429380-c568-47d8-a046-cf330bed6096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your question for the retrieaval and LLM\n",
    "question = \"Who is responsible for the mess?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b299c-8894-4bcb-a957-8a02aaac1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change local models\n",
    "LLM_name =\"gemma2\"\n",
    "embedder_name = \"deepvk/USER-bge-m3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a2e2a-cc31-4eba-a2e8-853f4550e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify prompt template for LLM\n",
    "prompt = \"\"\"\n",
    "1. Используй контекст, чтобы ответить на вопрос в конце.\n",
    "2. Если ты не знаешь ответа - говори \"Я не знаю\", не придумывай ответ если не уверена в нем.\n",
    "3. Старайся отвечать максимально подробно, так, чтобы человек получил исчерпывающий ответ на свой вопрос по документам.  \n",
    "\n",
    "Контекст: {context}\n",
    "\n",
    "Вопрос: {question}\n",
    "\n",
    "Ответ:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f862ce-e1f1-41d5-8c04-29be90b17c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e291502-07f6-4680-9b55-20e78e54e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What LLM inference you would use?\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef5fa55-0b42-4aa2-a168-a0fa3bd96af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What chat functions do you need for demo?\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c152c68e-69ee-43b1-bb0c-f48973aee426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How would you process pdf?\n",
    "from langchain_community.document_loaders import PDFPlumberLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab824de-3676-4dc0-9e97-734bb9f6fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How would you process docx files?\n",
    "from langchain_community.document_loaders import Docx2txtLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e48505-91db-4689-909f-93e025dcfd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What to use for text chunking and embeddings creation\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd6ef02-01e9-4893-9000-cf0fe8e1c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where to store embeddings?\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96582be1-b714-4589-9fac-17a55c262206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc55b0ee-c22e-43f5-9211-6b077c294ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#What local LLM would you like to boot?\n",
    "llm = Ollama(model=LLM_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fb10901-9044-499d-b4e5-11cdd11dd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where are your documents stored?\n",
    "documents_path = rag_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29ed3372-5c68-491f-9d77-86df08f5e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the relevant docs from main and sub directories\n",
    "msdocs_list = []\n",
    "pdfiles_list = []\n",
    "for path, subdirs, files in os.walk(documents_path):\n",
    "    for name in files:\n",
    "        if \".docx\" in name:\n",
    "            msdocs_list.append(os.path.join(path, name))\n",
    "        elif \".pdf\" in name:\n",
    "            pdfiles_list.append(os.path.join(path, name))\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c12b1f50-32dd-4376-a9bc-9048a19762d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all text and put into single file\n",
    "doc_list = []\n",
    "failed_list = []\n",
    "for doc in pdfiles_list:\n",
    "    try:\n",
    "        loader = PDFPlumberLoader(doc)\n",
    "        doc_list.append(loader.load())\n",
    "    except:\n",
    "        failed_list.append(doc)\n",
    "        continue\n",
    "\n",
    "for doc in msdocs_list[1:4]:\n",
    "    try:\n",
    "        loader = Docx2txtLoader(doc)\n",
    "        doc_list.append(loader.load())\n",
    "    except:\n",
    "        failed_list.append(doc)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e2fea2f-0f03-48f0-a672-e50a86054645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "C:\\Users\\Data Science\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Data Science\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Split all text into chunks and store them in a list. You can use your preffered chunking method instead of semantic chunker\n",
    "text_splitter = SemanticChunker(HuggingFaceEmbeddings(model_name=embedder_name,\n",
    "                                                      model_kwargs = {'device': 'cuda'}), \n",
    "                                breakpoint_threshold_type=\"percentile\",\n",
    "                               breakpoint_threshold_amount=60)\n",
    "\n",
    "chunk_list = []\n",
    "for doc in doc_list:\n",
    "    chunks = text_splitter.split_documents(doc)\n",
    "    chunk_list.append(chunks)\n",
    "chunk_list = [j for i in chunk_list for j in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5415319a-9123-4d54-83de-aa3d411940d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear model from GPU - can help with out-of-memory problems. Comment lines if not needed\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39bbc774-e456-4677-9639-d0d7bede4ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initiate the embedding model, which turn our chunks into vectors\n",
    "embedder = HuggingFaceEmbeddings(model_name=embedder_name,model_kwargs = {'device': 'cuda'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4453eeb-4195-432f-b43d-12d771396f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector storage for embeddings. You can choose whatever you like instead of FAISS\n",
    "vector = FAISS.from_documents(chunks, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0aa56e7-7fa8-459a-ad0c-48cef6fe569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the same database as vector search engine\n",
    "retriever = vector.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9c2c05be-7e0f-46a9-8a8b-e896bf7323cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config for LLM\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(prompt) \n",
    "\n",
    "llm_chain = LLMChain(\n",
    "                  llm=llm, \n",
    "                  prompt=QA_CHAIN_PROMPT, \n",
    "                  callbacks=None, \n",
    "                  verbose=True )\n",
    "\n",
    "document_prompt = PromptTemplate(\n",
    "    input_variables=[\"page_content\", \"source\"],\n",
    "    template=\"Context:\\ncontent:{page_content}\\nsource:{source}\",\n",
    ")\n",
    "\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "                  llm_chain=llm_chain,\n",
    "                  document_variable_name=\"context\",\n",
    "                  document_prompt=document_prompt,\n",
    "                  callbacks=None,\n",
    "              )\n",
    "\n",
    "qa = RetrievalQA(\n",
    "                  combine_documents_chain=combine_documents_chain,\n",
    "                  verbose=True,\n",
    "                  retriever=retriever,\n",
    "                  return_source_documents=True,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f650d6d8-ce2b-4930-8e69-1be53c5a7bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "38540c82-4349-4e80-9f3f-64a2d2e9e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "835240cd-0708-4608-95bb-b194ef220dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "1. Используй контекст, чтобы ответить на вопрос в конце.\n",
      "2. Если ты не знаешь ответа - говори \"Я не знаю\", не придумывай ответ если не уверена в нем.\n",
      "3. Старайся отвечать максимально подробно, так, чтобы человек получил исчерпывающий ответ на свой вопрос по документам.  \n",
      "4. Если ты заметишь логическое или фактическое противоречие в представленном контексте - обязательно скажи об этом пользователю.\n",
      "\n",
      "Контекст: Context:\n",
      "content:Блок-схема модели мониторинга уровня стресса.\n",
      "source:C:\\Users\\Data Science\\Downloads\\218_Программисты\\218_Программисты\\04 Отчетная документация\\2 этап\\2 этап_Для загрузки_Версия 2\\03.G25.31.0247-2.1.1.3. PZ na model stressa-2.docx\n",
      "\n",
      "Context:\n",
      "content:В этом случае возникает необходимость исключения каких-либо параметров, имеющих высокую взаимную коррелированность. Таблица 3.13.Регистрируемые биометрические параметры базовой многопараметрической модели \n",
      "\n",
      "Функциональное состояние\n",
      "\n",
      "Регистрируемые биометрические параметры ЭЭГ\n",
      "\n",
      "Когнитивная нагрузка\n",
      "\n",
      "-\n",
      "\n",
      "Стресс\n",
      "\n",
      "+\n",
      "\n",
      "Характер интеллектуальной деятельности\n",
      "\n",
      "-\n",
      "\n",
      "Ритм интеллектуальной деятельности\n",
      "\n",
      "-\n",
      "\n",
      "\n",
      "\n",
      "Выходные данные модели мониторинга стресса должны формироваться на основе регистрации, обработки и анализа входных данных электроэнцефаллограммы (таблица 3.14):\n",
      "\n",
      "Выходные данные должны представлять собой интегральные показатели определенного функционального состояния, либо отражать динамику его изменения. Таблица 3.14.Входные и выходные данные для базовой многопараметрической модели \n",
      "\n",
      "Показатель\n",
      "\n",
      "Входные данные\n",
      "\n",
      "Выходные данные\n",
      "\n",
      "ЭЭГ\n",
      "\n",
      "\tЧастотные диапазоны:  тета- (4-8 Гц), альфа- (8-13 Гц), бета-ритмы (13-20 Гц). Мощность ритмов \n",
      "\n",
      "\tПоказатель депрессии \n",
      "альфа-ритма\n",
      "\n",
      "\tСуммарная мощность ритмов ЭЭ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tЗАКЛЮЧЕНИЕ    \n",
      "\n",
      "В состав модели мониторинга стресса первоначально были включены следующие элементы: исходные данные, индексы, триггеры, сообщения. Исходные данные:\n",
      "\n",
      "Показатель электрической проводимости кожи между двумя электродами\n",
      "\n",
      "Промежуток между двумя  последовательными R зубцами на записи\n",
      "\n",
      "Поток сигнала с электрода в точке F7 по системе 10-20\n",
      "\n",
      "Поток сигнала с электрода в точке F7 по системе 10-20 \n",
      "\n",
      "Поток сигнала с электрода в точке F7 по системе 10-20\n",
      "\n",
      "Поток сигнала с электрода в точке F7 по системе 10-20\n",
      "\n",
      "Индексы:\n",
      "\n",
      "Средняя длительность RR-интервала\n",
      "\n",
      "Частота сердечных сокращений\n",
      "\n",
      "Стандартное отклонение RR\n",
      "\n",
      "Среднеквадратичное различие между длительностью соседних R-R интервалов\n",
      "\n",
      "Процент последовательных интервалов RR с разницей >50мс от общего количества RR интервалов\n",
      "\n",
      "Индекс напряжения Баевского\n",
      "\n",
      "Индекс асимметрии\n",
      "\n",
      "Усредненная электродермальная активность кожи (ЭДА)\n",
      "\n",
      "Триггеры:\n",
      "\n",
      "Рост ЭДА\n",
      "\n",
      "Асимметрия с преобладанием правополушарной активности\n",
      "\n",
      "Рост индекса напряжения Баевского\n",
      "\n",
      "Длительное изменение показателей сердечной активности\n",
      "\n",
      "Сообщения:\n",
      "\n",
      "Уведомление о стрессе сердечно-сосудистой системы\n",
      "\n",
      "Рост эмоциональной активности\n",
      "\n",
      "Высокий индекс напряжения\n",
      "\n",
      "С целью выбора и обоснования предпочтительного варианта сочетаний элементов модели, была произведена экспериментальная апробация модели. На основе анализа результатов эксперимента наиболее надежными признаны показатели, связанные с биоэлектрической активностью мозга (показатели когнитивной нагрузки и показатели эмоционального напряжения).\n",
      "source:C:\\Users\\Data Science\\Downloads\\218_Программисты\\218_Программисты\\04 Отчетная документация\\2 этап\\2 этап_Для загрузки_Версия 2\\03.G25.31.0247-2.1.1.3. PZ na model stressa-2.docx\n",
      "\n",
      "Context:\n",
      "content:Выбран и обоснован предпочтительный вариант построения модели уровня стресса и минимизации стрессогенных факторов в процессе интеллектуальной деятельности. Назначение и область применения модели мониторинга уровня стресса и минимизации стрессогенных факторов\n",
      "\n",
      "Назначение модели мониторинга уровня стресса и минимизации стрессогенных факторов\n",
      "\n",
      "Функциональное назначение модели мониторинга уровня стресса и минимизации стрессогенных факторов – моделирование процессов, связанных с диагностикой, контролем и управлением психоэмоциональными состояниями, в объёме, достаточном для реализации алгоритмов автоматизированной поддержки этих процессов. Разрабатываемая модель мониторинга уровня стресса и минимизации стрессогенных факторов предназначена для построения на её основе программных алгоритмов в составе аппаратно-программного комплекса для регистрации и анализа электрофизиологических и биометрических параметров человека, обеспечивающего повышение производительности интеллектуального труда. Область применения модели мониторинга уровня стресса и минимизации стрессогенных факторов\n",
      "\n",
      "Модель мониторинга уровня стресса и минимизации стрессогенных факторов может быть использована для реализации аппаратно-программных комплексов и отдельных программных и аппаратных решений, направленных на повышение производительности интеллектуального труда работников инженерных специальностей. Кроме того, модель может быть полезна при создании аналогичных технических решений для повышения производительности интеллектуального труда для других категорий работников. Техническая характеристика\n",
      "\n",
      "Выбор возможных решений модели мониторинга уровня стресса и минимизации стрессогенных факторов \n",
      "\n",
      "Описание подхода к выбору и обоснованию возможных решений построения модели\n",
      "\n",
      "Теоретическое обоснование модели\n",
      "\n",
      "Изменения в продуктивности деятельности у людей могут быть связаны не только с когнитивными характеристиками или общим изменением функционального состояния, но и с чрезмерным повышением уровня активации (в соответствии с законом Йеркса-Додсона об оптимальном уровне активации) в условиях кратковременного стресса, а также со снижением мотивационной составляющей деятельности в случае продолжительного стресса. Традиционно объективный уровень стресса измеряется с помощью регистрации показателей вегетативной нервной системы и анализом баланса вклада симпатической и парасимпатической активации.\n",
      "source:C:\\Users\\Data Science\\Downloads\\218_Программисты\\218_Программисты\\04 Отчетная документация\\2 этап\\2 этап_Для загрузки_Версия 2\\03.G25.31.0247-2.1.1.3. PZ na model stressa-2.docx\n",
      "\n",
      "Context:\n",
      "content:Однако, данные свидетельствуют также о высокой интериндивидуальной вариабельности. Наличие выраженной вариабельности между людьми свидетельствуют о возможных трудностях при поисках универсальных автоматизируемых показателей стресса. После анализа значимости измеряемых показателей, индексов и триггеров для эффективности модели мониторинга и оптимизации когнитивной нагрузки, была построена оптимизированная модель (рис.\n",
      "source:C:\\Users\\Data Science\\Downloads\\218_Программисты\\218_Программисты\\04 Отчетная документация\\2 этап\\2 этап_Для загрузки_Версия 2\\03.G25.31.0247-2.1.1.3. PZ na model stressa-2.docx\n",
      "\n",
      "Context:\n",
      "content:Определены критерии выбора показателей для оценки уровня стресса, выбраны и обоснованы измеряемые данные, триггеры срабатывания и сообщения обратной связи.\n",
      "source:C:\\Users\\Data Science\\Downloads\\218_Программисты\\218_Программисты\\04 Отчетная документация\\2 этап\\2 этап_Для загрузки_Версия 2\\03.G25.31.0247-2.1.1.3. PZ na model stressa-2.docx\n",
      "\n",
      "Вопрос: Какие требования были к модели стресса?\n",
      "\n",
      "Ответ:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "В тексте сказано, что модель мониторинга уровня стресса должна  моделировать процессы, связанные с диагностикой, контролем и управлением психоэмоциональными состояниями. \n",
      "\n",
      "Также она должна обеспечивать повышение производительности интеллектуального труда, а значит строиться на основе программных алгоритмов в составе аппаратно-программного комплекса для регистрации и анализа электрофизиологических и биометрических параметров человека.\n",
      "\n",
      "\n",
      "Модель должна быть полезна при создании технических решений для повышения производительности интеллектуального труда для разных категорий работников. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ask the question\n",
    "print(qa(question)[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59257e8e-32c8-44ca-a043-5c69505ee47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fea79-dce1-49fc-acb8-9aa4ba7c3207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langRAG",
   "language": "python",
   "name": "langrag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
